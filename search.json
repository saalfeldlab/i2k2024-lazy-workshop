[
  {
    "objectID": "posts/01-setup.html",
    "href": "posts/01-setup.html",
    "title": "Setup instructions",
    "section": "",
    "text": "We will do this workshop in Jupyter notebooks\nIn this workshop, we will learn how to use ImgLib2, BigDataViewer, the N5-API, and Apache Spark for lazy evaluation data processing workflows. We will draft all examples in interactive Jupyter notebooks. For this, we will need to create an environment that runs a Jupyter notebook server, a fast Java kernel, and a few other dependencies. If you don’t have conda installed yet, please do this now by following their installation instructions.\nNow, we can create an environment:\nconda create -c conda-forge -n i2k2024-lazy python=3\nand activate it:\nconda activate i2k2024-lazy\nNow, let’s install the Blosc compression library, the IJava Jupyter kernel, and a modern version of OpenJDK:\nconda install conda-forge::python-blosc\nconda install conda-forge::ijava\nconda install conda-forge::openjdk\nNow, checkout the repository with the code example for our workshop:\ngit clone https://github.com/saalfeldlab/i2k2024-lazy-workshop\nThis repository includes the notebooks for our workshop and renders them into a web-blog using the Quarto publishing system. For our workshop, it is not important to run Quarto, but you may find it exciting to use the same structure for your own experiments. You will find the notebooks as posts in the repository:\ncd i2k2024-lazy-workshop/posts\nHere, please start your Jupyter notebook server and let’s open the first example:\njupyter notebook\nPS: The IJava kernel uses Java’s JShell tool, so in a production environment, you can use JShell and Maven to execute your code. For that, you will have to declare the dependencies in a pom.xml file, and start JShell by:\nmvn com.github.johnpoth:jshell-maven-plugin:1.3:run"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Lazy Parallel Processing and Visualization of Large Data with ImgLib2, BigDataViewer, the N5-API, and Spark",
    "section": "",
    "text": "Setup instructions\n\n\n\n\n\n\nconda\n\n\njava\n\n\nijava\n\n\njupyter\n\n\nquarto\n\n\n\nHow to get started …\n\n\n\n\n\nOct 17, 2024\n\n\nStephan Saalfeld\n\n\n\n\n\n\n\n\n\n\n\n\nHow to work with the N5 API and ImgLib2?\n\n\n\n\n\n\nimglib2\n\n\njava\n\n\nn5\n\n\nhdf5\n\n\nzarr\n\n\njupyter\n\n\nnotebook\n\n\n\nRead and write ImgLib2 data with the N5 API.\n\n\n\n\n\nOct 17, 2024\n\n\nStephan Saalfeld\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/02-n5/2022-09-27-n5-imglib2.html",
    "href": "posts/02-n5/2022-09-27-n5-imglib2.html",
    "title": "How to work with the N5 API and ImgLib2?",
    "section": "",
    "text": "In this notebook, we will learn how to work with the N5 API and ImgLib2.\nThe N5 API unifies block-wise access to potentially very large n-dimensional data over a variety of storage backends. Those backends currently are the simple N5 format on the local filesystem, Google Cloud and AWS-S3, the HDF5 file format and Zarr. The ImgLib2 bindings use this API to make this data available as memory cached lazy cell images through ImgLib2.\nThis notebook uses code and data examples from the ImgLib2 large data tutorial I2K2020 workshop (GitHub repository).\nFirst let’s add the necessary dependencies. We will load the n5-ij module which will transitively load ImgLib2 and all the N5 API modules that we will be using in this notebook. It will also load ImageJ which we will use to display data. If this is the first time you are loading dependencies, running this can take quite a while. Next time, everything will be cached though…\n\n\nCode\n%mavenRepo scijava.public https://maven.scijava.org/content/groups/public\n%maven org.janelia.saalfeldlab:n5-ij:4.2.5\n\n\nNext, we register a simple renderer that uses ImgLib2’s ImageJ bridge and Spencer Park’s image renderer to render the first 2D slice of a RandomAccessibleInterval into the notebook. We also add a renderer for arrays and maps, because we want to list directories and attributes maps later.\n\n\nCode\nimport com.google.gson.*;\nimport io.github.spencerpark.jupyter.kernel.display.common.*;\nimport io.github.spencerpark.jupyter.kernel.display.mime.*;\nimport net.imglib2.img.display.imagej.*;\nimport net.imglib2.view.*;\nimport net.imglib2.*;\n\ngetKernelInstance().getRenderer().createRegistration(RandomAccessibleInterval.class)\n    .preferring(MIMEType.IMAGE_PNG)\n    .supporting(MIMEType.IMAGE_JPEG, MIMEType.IMAGE_GIF)\n    .register((rai, context) -&gt; Image.renderImage(\n        ImageJFunctions.wrap(rai, rai.toString()).getBufferedImage(),\n        context));\n\ngetKernelInstance().getRenderer().createRegistration(String[].class)\n    .preferring(MIMEType.TEXT_PLAIN)\n    .supporting(MIMEType.TEXT_HTML, MIMEType.TEXT_MARKDOWN)\n    .register((array, context) -&gt; Text.renderCharSequence(Arrays.toString(array), context));\n\ngetKernelInstance().getRenderer().createRegistration(long[].class)\n    .preferring(MIMEType.TEXT_PLAIN)\n    .supporting(MIMEType.TEXT_HTML, MIMEType.TEXT_MARKDOWN)\n    .register((array, context) -&gt; Text.renderCharSequence(Arrays.toString(array), context));\n\ngetKernelInstance().getRenderer().createRegistration(Map.class)\n    .preferring(MIMEType.TEXT_PLAIN)\n    .supporting(MIMEType.TEXT_HTML, MIMEType.TEXT_MARKDOWN)\n    .register((map, context) -&gt; Text.renderCharSequence(map.toString(), context));\n\n\nWe will now open N5 datasets from some sources as lazy-loading ImgLib2 cell images. For opening the N5 readers, we will use the helper class N5Factory which parses the URL and/ or some magic byte in file headers to pick the right reader or writer for the various possible N5 backends. If you know which backend you are using, you should probably use the appropriate implementation directly, it’s not difficult.\n\n\nCode\nimport ij.*;\nimport net.imglib2.converter.*;\nimport net.imglib2.type.numeric.integer.*;\nimport org.janelia.saalfeldlab.n5.*;\nimport org.janelia.saalfeldlab.n5.ij.*;\nimport org.janelia.saalfeldlab.n5.imglib2.*;\nimport org.janelia.saalfeldlab.n5.universe.*;\n\n/* make an N5 reader, we start with a public container on AWS S3 */\nfinal var n5Url = \"https://janelia-cosem.s3.amazonaws.com/jrc_hela-2/jrc_hela-2.n5\";\nfinal var n5Group = \"/em/fibsem-uint16\";\nfinal var n5Dataset = n5Group + \"/s4\";\nfinal var n5 = new N5Factory().openReader(n5Url);\n\n/* open a dataset as a lazy loading ImgLib2 cell image */\nfinal RandomAccessibleInterval&lt;UnsignedShortType&gt; rai = N5Utils.open(n5, n5Dataset);\n\n/* This is a 3D volume, so let's show the center slice */\nViews.hyperSlice(rai, 2, rai.dimension(2) / 2);\n\n\nSLF4J: Failed to load class \"org.slf4j.impl.StaticLoggerBinder\".\nSLF4J: Defaulting to no-operation (NOP) logger implementation\nSLF4J: See http://www.slf4j.org/codes.html#StaticLoggerBinder for further details.\n\n\n\n\n\n\n\n\n\nThat’s a bit low on contrast, let’s make it look like TEM, and let’s show a few of those hyperslices through the 3D volume:\n\n\nCode\nvar raiContrast = Converters.convert(\n    rai,\n    (a, b) -&gt; b.setReal(\n        Math.max(\n            0,\n            Math.min(\n                255,\n                255 - 255 * (a.getRealDouble() - 26000) / 6000))),\n    new UnsignedByteType());\ndisplay(Views.hyperSlice(raiContrast, 2, rai.dimension(2) / 10 * 4), \"image/jpeg\");\ndisplay(Views.hyperSlice(raiContrast, 2, rai.dimension(2) / 2), \"image/jpeg\");\ndisplay(Views.hyperSlice(raiContrast, 2, rai.dimension(2) / 10 * 6), \"image/jpeg\");\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n9465564d-db0b-4f2a-8643-483b0b624b5d\n\n\nWe can list the attributes and their types of every group or dataset, and read any of them into matching types:\n\n\nCode\nvar groupAttributes = n5.listAttributes(n5Group);\nvar datasetAttributes = n5.listAttributes(n5Dataset);\n\ndisplay(\n    \"**\" + n5Group + \"** attributes are ```\" +\n        groupAttributes.toString().replace(\", \", \",\\n\").replace(\"{\", \"{\\n\") + \"```\",\n    \"text/markdown\");\ndisplay(\n    \"**\" + n5Dataset + \"** attributes are ```\" +\n        datasetAttributes.toString().replace(\", \", \",\\n\").replace(\"{\", \"{\\n\") + \"```\",\n    \"text/markdown\");\n\nvar n5Version = n5.getAttribute(\"/\", \"n5\", String.class);\nvar dimensions = n5.getAttribute(n5Dataset, \"dimensions\", long[].class);\nvar compression = n5.getAttribute(n5Dataset, \"compression\", Compression.class);\nvar dataType = n5.getAttribute(n5Dataset, \"dataType\", DataType.class);\n\ndisplay(n5Version);\ndisplay(dimensions);\ndisplay(compression);\ndisplay(dataType);\n\n\n/em/fibsem-uint16 attributes are { pixelResolution=class java.lang.Object, multiscales=class [Ljava.lang.Object;, n5=class java.lang.String, scales=class [Ljava.lang.Object;, axes=class [Ljava.lang.String;, name=class java.lang.String, units=class [Ljava.lang.String;}\n\n\n/em/fibsem-uint16/s4 attributes are { transform=class java.lang.Object, pixelResolution=class java.lang.Object, dataType=class java.lang.String, name=class java.lang.String, compression=class java.lang.Object, blockSize=class [J, dimensions=class [J}\n\n\n2.0.0\n\n\n[750, 100, 398]\n\n\norg.janelia.saalfeldlab.n5.GzipCompression@2667385a\n\n\nuint16\n\n\nb100f1ac-ad8d-4f08-975b-41195e07f607\n\n\nLet’s save the contrast adjusted uin8 version of the volume into three N5 supported containers (N5, Zarr, and HDF5), parallelize writing for N5 and Zarr:\n\n\nCode\nimport java.nio.file.*;\n\n/* create a temporary directory */\nPath tmpDir = Files.createTempFile(\"\", \"\");\nFiles.delete(tmpDir);\nFiles.createDirectories(tmpDir);\nvar tmpDirStr = tmpDir.toString();\n\ndisplay(tmpDirStr);\n\n/* get the dataset attributes (dataType, compression, blockSize, dimensions) */\nfinal var attributes = n5.getDatasetAttributes(n5Dataset);\n\n/* use 10 threads to parallelize copy */\nfinal var exec = Executors.newFixedThreadPool(10);\n\n/* save this dataset into a filsystem N5 container */\ntry (final var n5Out = new N5Factory().openFSWriter(tmpDirStr + \"/test.n5\")) {\n  N5Utils.save(\n      raiContrast,\n      n5Out,\n      n5Dataset,\n      attributes.getBlockSize(),\n      attributes.getCompression(),\n      exec);\n}\n\n/* save this dataset into a filesystem Zarr container */\ntry (final var zarrOut = new N5Factory().openZarrWriter(tmpDirStr + \"/test.zarr\")) {\n  N5Utils.save(\n      raiContrast,\n      zarrOut,\n      n5Dataset,\n      attributes.getBlockSize(),\n      attributes.getCompression(),\n      exec);\n}\n\n/* save this dataset into an HDF5 file, parallelization does not help here */\ntry (final var hdf5Out = new N5Factory().openHDF5Writer(tmpDirStr + \"/test.hdf5\")) {\n  N5Utils.save(\n      raiContrast,\n      hdf5Out,\n      n5Dataset,\n      attributes.getBlockSize(),\n      attributes.getCompression());\n}\n\n/* shot down the executor service */\nexec.shutdown();\n\ndisplay(Files.list(tmpDir).map(a -&gt; a.toString()).toArray(String[]::new));\n\n\n/tmp/2846400809626417080\n\n\n[/tmp/2846400809626417080/test.n5, /tmp/2846400809626417080/test.zarr, /tmp/2846400809626417080/test.hdf5]\n\n\na8de8788-6074-4bd8-adf4-256f26bf1274\n\n\nNow let us look at them and see if they all contain the same data:\n\n\nCode\ntry (final var n5 = new N5Factory().openReader(tmpDirStr + \"/test.n5\")) {\n  final RandomAccessibleInterval&lt;UnsignedByteType&gt; rai = N5Utils.open(n5, n5Dataset);\n  display(Views.hyperSlice(rai, 2, rai.dimension(2) / 2), \"image/jpeg\");\n}\n\ntry (final var n5 = new N5Factory().openReader(tmpDirStr + \"/test.zarr\")) {\n  final RandomAccessibleInterval&lt;UnsignedByteType&gt; rai = N5Utils.open(n5, n5Dataset);\n  display(Views.hyperSlice(rai, 2, rai.dimension(2) / 2), \"image/jpeg\");    \n}\n\ntry (final var n5 = new N5Factory().openReader(tmpDirStr + \"/test.hdf5\")) {\n  final RandomAccessibleInterval&lt;UnsignedByteType&gt; rai = N5Utils.open(n5, n5Dataset);\n  display(Views.hyperSlice(rai, 2, rai.dimension(2) / 2), \"image/jpeg\");        \n}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLet’s clean up temporary storage before we end this tutorial.\n\n\nCode\ntry (var n5 = new N5Factory().openWriter(tmpDirStr + \"/test.n5\")) {\n  n5.remove();\n}\ntry (var n5 = new N5Factory().openWriter(tmpDirStr + \"/test.zarr\")) {\n  n5.remove();\n}\ntry (var n5 = new N5Factory().openWriter(tmpDirStr + \"/test.hdf5\")) {\n  n5.remove();\n}\nFiles.delete(tmpDir);"
  }
]